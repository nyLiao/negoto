# Requirements Analysis Document 需求分析文档

## 项目背景

### 文档引言

自然语言处理（Natural Language Processing, NLP）被誉为人工智能技术的一颗明珠，而自然语言生成（Natural Language Generation, NLG）则是 NLP 中最为困难也最有吸引力的课题之一。NLG 方向以往少有进展，近年来，得益于深度学习等技术的发展，出现了不少将新技术和模型应用于 NLG 的尝试。OpenAI 发布的模型 GPT 及其后继者 GPT-2 是其中的典型，其由于优秀的摘要和新闻生成表现，甚至被称为 “too dangerous to release”。因此，研究实现 GPT-2 模型对中文文本语料的生成，也是一项非常有趣的工作。

### 项目说明

项目名称为 negoto，项目描述为基于 GPT-2 模型的文本生成器，概念图标如下图所示。

![Thinking Bubble icon by Icons8](icon.png)

项目为 IS305 应用软件课程设计的小作业，项目内的各项工作由本人完成。

### 类似项目

#### BullshitGenerator

「狗屁不通文章生成器」（[GitHub](https://github.com/menzi11/BullshitGenerator)），由 [menzi11](https://github.com/menzi11) 开发并开源。项目使用简单随机组合算法，配合内置的成句语料，对给定文章标题迅速生成大量文本。项目因其趣味性，曾一度登上 GitHub Trending Repositories 首位。

#### 九歌

「九歌」人工智能诗歌写作系统（[网页](https://jiuge.thunlp.cn/)），由清华 NLP 实验室开发，代码不开源。项目基于 GPT-2 等生成模型，对输入的标题和格式，生成符合格律的诗词，具有多模态输入、多体裁多风格、人机交互创作模式等特点。

### 参考资料

* OpenAI 官方 GPT-2 模型项目（[GitHub](https://github.com/openai/gpt-2)）

* GPT-2 中文模型部署实现项目（[GitHub](https://github.com/Morizeyao/GPT2-Chinese)）

----------------------------------------
## 项目概述

### 项目定位

#### 面向人群

项目面向需要简单应用人工智能技术生成长语料的普通人群，使用者无需具备搭建及运行神经网络模型的背景知识技能。

#### 主要功能

项目提供并封装使用特定应用文语料训练的 GPT-2 模型，使用者可通过桌面应用程序图形用户界面，按需逐段生成中文文本。

#### 项目特色

* **多段生成：** 项目通过依次输入段首提示词（可为空）逐段生成文本，使段内语义更加可控。另一方面，项目能实现模型缓存过往状态，从而使模型在前文语境下生成新文本，段间具有连续性。

* **参数可调：** 项目可通过图形界面动态地调整模型生成中相关参数，从而实现对生成文本的长度、可靠程度等属性的细致调控。

* **文章控制：** 项目能实现对各文段及全文的编辑、清除、重新生成、导出等的图形界面操作，使用户能获得满意的整篇文章。

### 应用场景

* **文章写作：** 所生成文本语句通顺、符合语境、重复性低，可用于质量要求不高的特定类型长文章写作，如一些不会被认真审阅的感想、计划、总结等。

* **语料生成：** 较快地生成特定题材的大量文本语料，以供 NLP 等方向的研究应用。

* **文字渲染：** 生成大量成段符合文法的文字，以供各种文字占位符、渲染测试使用。

### 展望改进

* **界面交互：** 使用更好的程序平台和 UI 设计，提供更加丰富、友好的用户功能。

* **效果提升：** 增加语料的数量和范畴，优化清洗训练方法，考虑使用容量更大的 GPT-2 模型，以提升生成文本的通顺性、切题性等效果。

* **性能优化：** 考虑进行模型压缩与加速，以优化提升模型推断的性能。

### 项目目标

项目旨在开发一款完整的桌面应用程序，基于 NLG 技术的 GPT-2 模型，实现生成中文语料的文本生成器。

按架构划分，项目主要有如下阶段性目标：

* **语料：** 获取一定量、特定题材的中文应用文文本语料，清洗处理后供模型进行训练。

* **模型：** 搭建 GPT-2 中文模型及相关分词器等，选取适当超参数并训练模型，评估模型表现并部署模型生成功能。

* **应用：** 开发用户界面，处理应用程序进程与模型生成进程通信，最终打包为完整的桌面应用程序。

* **文档：** 项目开发全程的代码风格控制，课程小作业及项目开源需要的相关文档写作，课程展示及提价所需的 PPT 和录屏制作。

### 项目限制

* **时间安排：** 需要在小作业展示及提交截止前完成相关要求。

* **计算资源：** 训练模型的服务器资源有限。

----------------------------------------
## 功能需求

### 功能描述

#### 文本生成

* 输入：用户在输入框内输入的提示词，并点击生成按键。

* 处理：应用调用模型生成方法，将提示词及当前参数作为参数传递；模型根据提示词、参数及历史状态，生成一段文本并处理成符合格式的段落返回；同时交互通信以在生成完成前显示进度条。

* 输出：输出框生成完成前显示进度条，完成后显示生成的一段文本段落。

#### 参数调整

* 输入：用户对工具栏内参数控件的调整。

* 处理：更改参数显示值，并及时更新后端参数实际值。

* 输出：工具栏参数显示处的参数当前值。

#### 等待状态

* 输入：无。在无法调用模型生成方法时触发，如导入模型，及模型正在生成时。

* 处理：更改控件状态，同时检测模型状态以取消等待状态。

* 输出：禁用生成按键，显示等待状态动画。

#### 段落清除

* 输入：用户点击段落下方清除按键。

* 处理：清除该段落的输入输出内容。

* 输出：清除后空的输入输出文本框。

#### 段落增加

* 输入：用户点击工具栏内段落增加按键。

* 处理：渲染添加相关段落元素，绑定相关控件行为。

* 输出：列表末尾增加一个段落的文本框及按键等。

#### 文章清空

* 输入：用户点击工具栏内文章清空按键。

* 处理：清除所有段落的输入输出内容，并调用模型清除历史状态方法。

* 输出：清除后空的文章段落列表。

#### 文章导出

* 输入：用户点击工具栏内文章导出按键。

* 处理：整合所有段落的生成文本，保存为文本文件。

* 输出：保存并打开的导出文章文件。

### 业务流程

1. 用户下载安装本程序及相关依赖，设置好模型。

1. 用户打开程序，开始加载子进程，进行模型导入及通信服务建立；同时显示用户界面，用户界面在子进程加载完成前提示为等待状态。

1. （可选）用户设置相关参数、调整段落等，界面进行相应渲染调整。

1. （可选）用户输入段落开头提示词。用户点击生成键，应用获取处理提示词及当前参数，调用模型生成段落并展示，同时交互通信以在生成完成前显示进度条。

1. 用户清除、编辑段落，清空、导出文章等，应用进行响应。

1. 用户退出程序，关闭窗口，并结束子进程。

### 用户界面

#### 整体风格

符合桌面应用程序风格，符合运行平台 UI 特点。单窗口应用，有基本的调整、关闭、菜单等功能。

#### 组成元素

##### 顶部工具栏

顶部工具栏包括涉及整篇文章的一些操作，包括：

* **段落增加按键：** 在列表末尾新增一个段落。

* **文章清空按键：** 清除所有段落内容，并重置模型。

* **文章导出按键：** 将所有段落导出为一篇文章，并保存文件。

* **参数调节按键组：** 使用滑动条调节各生成参数，并显示参数值、说明文字等。

    * **字数调节按键：** 调节生成段落的最大长度。

    * **温度调节按键：** 调节生成时温度参数，改变生成文本的相对启发性。

    * **Top-k调节按键：** 调节 top-k 方法筛选参数，改变所生成的候选文本个数。

    * **Top-p调节按键：** 调节 top-p 方法筛选参数，改变候选文本累积概率下限。

##### 文章段落列表

文章段落列表包括各个段落的文本框及按键等元素：

* **输入文本框：** 可编辑文本框，提示用户在此输入段落开头。

* **输出文本框：** 可编辑文本框，展示生成文本结果；生成时禁用并显示进度条。

* **段落清除按键：** 清除该段落输入输出文本框内容。

* **段落生成按键：** 根据当前输入提示词及参数组合生成段落；等待状态无法生成时禁用并显示等待状态动画。

----------------------------------------
## 其他需求

### 运行环境

#### 操作系统

能在开发平台，即  Mac OS X 10.15 上运行。若有可能也可进行跨平台适配。

#### 相关依赖

* GPT-2 模型推断时所需 Python 包，主要是 `torch, transformers`。

* 若打包发布应用，则要求能运行 Electron 应用即可。

### 相关接口

* 需要将训练好的 GPT-2 模型及配置、词表、接口文件存放于指定路径下。

* 导出文本文件的默认路径为本目录下 `./outputs/output.txt`。

* 子进程通信服务需要使用本地回环地址 `127.0.0.1` 和端口 `6161`。

### 性能需求

* **空间：** 应用包含了一个神经网络，就研究测试阶段而言，网络约 400MB 的大小可以接受；但若应用需要发布，则需考虑文件大小的问题。

* **时间：** 由于文本生成涉及到神经网络模型的推断过程，因此需要在使用 GPU/CPU 进行运算时，将处理时间控制在可接受范围内。这方面限制了生成过程参数的范围。

* **效果：** NLG 生成自然语言文本，就正常人阅读文本的感性感受而言，需要对文本的内容有不同层次的要求：最基本的要求是语句无生成错误，符合文章段落格式；其次要求语句通顺，选词造句符合语境，且不因过拟合与训练文本雷同；更高层次的要求则包括句内及句间具有逻辑性等。这也对参数组合提出了要求。

### 反向需求

软件用户自由度较大，严格而言反向需求不显著。软件设计过程中采取了部分提示和强制措施防止用户进行无效操作。一个场景为应用启动初期模型未完成载入时，生成按钮禁用并显示动画，提示用户等待；另一场景为模型进行文本生成时，对应的输出框和生成按钮均禁用，且有进度提示，提供了良好的用户体验。

### 故障处理

由于 GPT-2 模型发布不久，关于输入历史状态进行文本推断的过程存在一些问题，在输入文本量过大（约 1000 字以上）时，性能急剧下降，甚至可能模型崩溃无法输出。本应用设置了自动处理机制，尽量避免了大文本输入，就文本推断过程进行了优化加速，同时处理普通的模型错误输出问题；在最坏情况下，可以通过文章清空按键手动重置模型，解决崩溃故障。做到故障处理尽量自动完成，对用户保持透明。

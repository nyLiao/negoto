# Software Design Document 软件设计文档

## 模块视图

### 模型模块

模型模块部分主要围绕 GPT-2 中文模型进行设计，主要部分为训练好的模型推断的实现，开发过程中还包括模型的搭建、训练、评估等流程。

#### 实现机制

* 该部分主要采用 Python 语言开发。

* 模型的整个部署过程使用机器学习框架 PyTorch。

* 模型及分词器等部分采用 NLP 处理库 transformers 进行实现。

#### 模块接口

##### 进程间通信

模型模块作为子进程运行时，需要处理前端应用对模型的操作输入，并进行对应输出。该部分采用 Python 面向对象封装为一个模型类 `genModel`，主要提供以下调用方法：

* `genModel.gen_ph(inputs, length, topk, topp, temperature)`：根据输入提示词和参数生成段落，并返回段落文本字符串。

* `genModel.clear()`：清除模型历史状态。

##### 状态通信

状态通信主要输出模型模块的运行状态，采用 Python 直接输出。主要涉及以下情况：

* 模型导入及服务端建立状态：输出开始部署及部署完成的相关状态。

* 段落生成进度：输出已生成段落字数的百分比。

#### 数据结构

* 语料数据的存储为逐篇文章保存在 `.txt` 文件中；需要进行模型训练时，按训练要求先整合为一个 JSON 列表文件 `GPT2-Chinese/data/train.json`；再由分词器分词编码后保存于 `GPT2-Chinese/data/tokenized/` 目录下指定份数的 `.txt` 文件中。

### 应用模块

应用模块主要指 Electron 实现的应用程序前后端，涉及后端搭建、进程通信、前端设计等。

#### 实现机制

* 应用程序主体采用 Electron 框架，其采用 Chromium 内核，提供跨平台桌面 GUI 应用程序的开发。

    * Electron 后端为 Node.js，项目实现基本基于原生 JavaScript 和相关 Node 模块。

    * 前端采用 HTML5/CSS 编写。

* Python-Node.js 跨语言进程间通信主要采用 Thrift 框架，Python 模型模块作为服务端，Node 应用后端作为客户端。实际运行中，应用程序启动时调用 Node 子进程模块 `child_process` 运行 Python 模块子进程，在服务建立后 Node 客户端再进行连接，并通过 Thrift 通信。

#### 模块接口

##### 进程间通信

Node 后端负责处理 Python 模块相关接口的调用，后端将会实例化一个 `thriftClient` 对象，通过其在符合条件时调用模型对象 `genModel` 的相应方法：

* 需要生成一段落文本时，调用 `thriftClient.gen_ph()` 方法，返回值即为所生成的文本。

* 需要清除模型历史状态时，调用 `thriftClient.clear()` 方法。

##### 状态通信

Node 后端负责监听 Python 模块的状态输出。作为子进程，Python 模块的输出会被定向到标准输出流 `stdout` 中，Node 后端在输出流变化时，分析输出内容并作出响应：

* 模型导入完成，服务端建立完成：尝试客户端进行连接，若连接成功，停止应用等待状态。

* 带有生成进度标识：获取进度百分比，更新渲染进度条元素。

##### 文件接口

* 模型及配置、词表、接口文件需要存放在 `./GPT2-Chinese/` 目录下。

* 配置文件按模块默认路径在 `userData/electron-store.json` 中。

* 导出文本文件的默认路径为 `./outputs/output.txt`。

#### 数据结构

* Thrift 通信使用的底层数据结构为 JSON 列表，由 Thrift 框架处理其输入参数和输出字符串的存取。

----------------------------------------
## 开发视图

### 语料获取

1. 确定生成应用文的主题范围，搜索符合要求的范文网等网站。

1. 根据网站编写爬虫，获取一定数量的语料并保存。

1. 编写清洗规则，将语料处理后整合至 `train.json`。

### 模型训练

1. 按设计配置参数搭建模型。

1. 调用分词器分词，保存为各份训练用语料。

1. 调整训练轮数、学习率等参数，进行模型无监督学习，保存各轮模型。

1. 取部分语料，测试各轮模型 loss，平衡模型学习程度与过拟合程度，取较好者作为已训练模型。

### 模型部署

1. 编写模型推断程序，使模型能够根据输入及参数输出推断结果，并筛选后组成段落文本。编写处理规则，使符合段落格式。

1. 实现 `genModel` 类，实现按历史状态连续输出多个段落特性。

1. 实现相关接口，完成 Thrift 服务封装。

### 通信配置

1. 统一服务端与客户端接口，确定通信协议内容。

1. 按 Thrift 格式编写 `.thrift` 定义文件。

1. 使用 Thrift 生成两种语言的通信文件。

### 应用搭建

1. 搭建 Electron 应用基本框架，包括后端载入、窗口操作、前端基本框架等。

1. 实现通信相关接口，实现子进程启动与通信。

1. 添加用户界面元素，渲染器进行行为绑定。

1. 调试整体行为，完善用户体验。

### 前端设计

1. 搭建基本窗口，确定窗口尺寸、风格等。

1. 添加输入输出文本框元素，实现单个段落的输入与生成。

1. 添加列表元素，使用渲染器实现段落的动态添加、清空等。

1. 添加工具栏按键元素，实现参数的调整与传递、模型重置、导出文本等功能。

1. 优化页面与用户体验。

### 项目发布

1. 统一代码风格与注释。

1. 处理版本管理相关信息。

1. 制作文档、展示 PPT、视频等。

----------------------------------------
## 模型部署

### 语料获取

语料选取了 5 个范文网站的数千篇文章，处理后约 20MB，共分成 500 份。文章均为中文应用文，长度约数百至一千字，均有多个段落。出于版权考虑，暂不公开语料与相关资料。

文章题材方面，主要是有较明显特色与应用范围的心得体会、学习汇报、规划总结等；文章主体以大学生为主，内容积极向上，涉及热门话题、时事政治、影视文化、学习生活等方面。

数据清洗方面，主要基于如下规则：

* 消去爬取中遗留的网页 HTML 代码。

* 符合基本的段落格式、空白字符、标点符号。

* 统一列举、章节、编号格式。

* 遮盖难以学习的数字和专有名词内容。

### 模型训练

模型采用的是 GPT-2 124M 参数模型，大小约 400 MB，词表个数 21128 个。模型由 transformers 库搭建，由 [hughqiu](https://github.com/hughqiu) 在130MB 散文语料上进行了 10 轮预训练。模型采用 BERT 分词器处理中文字符，实现过程参考 [GPT-2 中文模型部署实现项目](https://github.com/Morizeyao/GPT2-Chinese)。

模型在预训练起点上，应用上述语料进行 10 轮 fine-tune，保存每轮训练结果。训练参数 `batch_size=2`，`learning rate=5.0e-5`，进行 2000 steps warm-up。模型在 NVIDIA GTX 1080 单 GPU 上训练全程约 5 小时。

### 模型评估

模型仍使用部分获取的语料进行评估，根据各轮训练模型 loss，平衡模型学习程度与过拟合程度，最终确定了待部署的模型。

针对该模型，平衡模型的创新性、可靠性与生成速度，确定了模型生成参数的较好范围。模型在 Intel Core i5 单 CPU 下进行生成，每 100 字用时 5～10 秒，就项目演示而言属于可接受范围。随语境复杂和模型历史状态增多，生成性能可能有所下降。

### 模型推断

实现接口类 `genModel` 及相关方法，主要代码见 `GPT2-Chinese/generate_class.py`。生成后格式处理部分，由词向量转换回中文字符后，处理遮盖数字和专有名词留下的 `[UNK]`，并在最后一个完整语句结束后截断。

实现 Thrift 服务封装，主要代码见 `./python/pyServer.py`。使用 `pyModelHandler` 类继承 `genModel` 类，并封装相关方法。按 Thrift 格式建立服务端进程。

段落生成部分，由于 Thrift 跨语言通信格式转换问题，所有输入文本和参数都处于 JSON 列表 `dic` 中，其作为参数传入 `pyModelHandler.py_gen_ph()` 方法后，在处理为相关数字或字符串。

----------------------------------------
## 应用程序

### 后端设计

#### Electron 配置

`package.json` 文件是 Electron 特有的配置文件，主要定义应用信息、Electron 命令、模块依赖等。安装程序执行 `npm install` 时，npm 即根据该文件中配置安装相关依赖。本地应用依赖模块在 `./node_modules` 目录下。

#### 应用主程序

主程序 `./index.js` 在 Electron 启动时开始执行。主程序定义了应用的管理及运行，窗口、菜单的行为，并启动管理子进程。主程序及其相关菜单控制程序 `./js/menu.js` 基于模版 [szwacz/electron-boilerplate](https://github.com/szwacz/electron-boilerplate)，包括了应用基本模块管理、窗口菜单管理、开发调试工具等。

主程序使用 `child_process.spawn()` 方法执行 Python 子进程，并使用 `-u` 参数使状态输出缓冲区及时清空，即时导向标准输出流。

#### 渲染器程序

渲染器程序 `./js/renderer.js` 由前端页面应用，在前端渲染时开始执行。其主要功能包括绑定用户界面各元素行为，以及建立管理进程间通信客户端。

渲染器内部的事件监听与处理主要使用 `events` 模块。

### 进程通信

#### 进程间通信

进程间通信使用 Thrift 实现，其通过传输层和应用层协议，实现了跨语言的服务提供。`./python/api.thrift` 接口文件定义了所提供的服务，这里主要是相关类方法的参数和返回值。

根据接口文件，运行 `./python/thrift_gen.sh` 脚本，使用 Thrift 编译生成 Node 和 Python 的接口文件，路径各为 `./js/gen_nodejs/` 和 `./python/gen_py/`。

##### 模型模块

`./python/pyServer.py` 中，载入 Thrift 库和接口文件，实例化接口类 `pyModelHandler`，配置并建立服务端进程。

##### 应用模块

渲染器程序 `./js/renderer.js` 中，载入接口文件，在应用主程序获知子进程载入完成后，尝试配置建立客户端，并与子进程服务端建立连接。客户端建立后，模型模块的接口即可调用客户端同名方法实现。

#### 状态通信

主程序 `./index.js` 在应用就绪时执行并监听 Python 子进程 `pyProc`。使用标准输出流方法 `stdout.on()` 在子进程有输出时，处理输出字符串并采取响应。

#### 内部通信

由于状态通信与子进程相关，由主程序负责，进程间通信与 Thrift 客户端相关，由渲染器程序负责，因此需要两个 Node 程序间通信传递状态。主进程程序 `index.js` 与前端渲染器程序 `renderer.js` 间通信使用配置文件存储模块 `electron-store` 实现，主要内容有：

* `serverStarted`：记录子进程服务是否建立的变量。在子进程状态输出服务建立信息后，主程序修改该变量值。渲染器程序使用 `electron-store` 提供的 `onDidChange()` 方法监听该变量，在值为真后尝试建立连接。

* `genProgress`：原设计用于记录生成进度的变量。实际中发现性能表现不佳，故采用主进程直接进行渲染绕过通信。

### 用户界面

#### 整体风格

前端页面采用 HTML5/CSS 编写。CSS 文件参考了 [connors/photon](https://github.com/connors/photon) UI 框架，其提供了类 OS X 桌面程序风格的部分 UI 元素设计。自定义的 UI 元素主要在 `./css/negoto_add.css` 中。

前端由于为单窗口应用，设计上力求简洁易用。采用大量通用的设计语言，如按键高亮、文本框提示符、说明文字等，提供完善的用户体验。

#### 顶部工具栏

顶部工具栏中主要为各按键元素。按键主要有两种，普通按键包括段落增加、文章清空、文章导出三个，带滑动条子页面的按键包括四个参数调节按键。

普通按键行为在渲染器程序中绑定，包括更改元素属性、调用通信客户端、执行子进程导出脚本等。段落增加按键实现了在渲染器程序中，使用原生 javaScript，动态添加列表元素，并绑定行为。

调节按键使用 CSS `:hover` 选择器，在鼠标位于按键上时，显示调节子页面，其主要内容包括滑动条及参数值的显示。

#### 文章段落列表

文章段落列表主要元素为输入输出文本框和段落清除、生成按键。

文本框定义了输入输出两个 CSS 类，方便格式调整以及渲染器元素选取。输入框默认大小为三行约 100 字；输出框为八行约 300 字，使得在默认参数设置下能显示完整文本，无需滑动；当然也有大小调整以及框内滚动条功能。

清除、生成按键与段落内元素绑定，其中，生成按键的实现为最复杂者之一。其实现了执行客户端生成段落方法、显示等待状态动画、显示进度条子页面等功能。由于 HTML 特性，在输出文本框由渲染器将生成文本填充时，不会触发任何默认事件，因此生成按键还负责在生成完成后，主动完成自定义事件监听器 `eventEmitter` 的触发与响应，停止状态动画、进度条显示。

----------------------------------------
## 文件列表

### 主目录
```
negoto
├── css
│   ├── fonts               // Photon 图标字体
│   │   └── ...
│   ├── negoto_add.css      // CSS 自定义元素
│   ├── photon.css          // Photon 元素
│   └── photon_icon.css     // Photon 图标元素
├── docs
│   ├── RAD.md              // 需求分析文档
│   ├── README.md           // 简介文档
│   ├── SDD.md              // 软件设计文档
│   └── ...
├── js
│   ├── gen_nodejs          // Thrift Node 接口文件
│   │   └── ...
│   ├── config.js           // electron-store 模块配置文件
│   ├── menu.js             // 菜单程序
│   └── renderer.js         // 渲染器程序
├── node_modules            // 本地 Node 模块
│   └── ...
├── outputs
│   ├── examples.md         // 不同参数组合输出样例
│   └── output.txt          // 默认导出文本文件
├── python
│   ├── gen_py              // Thrift Python 接口文件
│   │   └── ...
│   ├── api.thrift          // Thrift 定义脚本
│   ├── pyServer.py         // Thrift Python 服务封装
│   └── thrift_gen.sh       // Thrift 快速编译脚本
├── LICENSE
├── index.html              // 主要窗口前端
├── index.js                // 应用主程序
├── package.json            // Electron 包配置文件
├── requirements_full.txt   // Python 完整库依赖
└── requirements_gen.txt    // Python 仅生成功能库依赖

```

### 模型子模块目录
```
.
├── GPT2-Chinese
│   ├── cache               // 词表临时文件
│   │   ├── make_vocab.py
│   │   ├── make_vocab.sh
│   │   └── vocab.txt
│   ├── config              // 模型配置
│   │   └── model_config.json
│   ├── data
│   │   ├── tokenized       // 处理后语料
│   │   │   ├── tokenized_train_0.txt
│   │   │   ├── ...
│   │   │   └── tokenized_train_499.txt
│   │   ├── train.json      // 处理前语料
│   │   └── txt2json.ipynb  // 语料清洗整合程序
│   ├── model
│   │   ├── final_model     // 已训练模型（按 transformers 配置）
│   │   │   ├── config.json
│   │   │   ├── pytorch_model.bin
│   │   └── └── vocab.txt
│   ├── scripts             // 运行用脚本
│   │   ├── eval_batch.sh
│   │   ├── generate.sh
│   │   ├── generate_texts.sh
│   │   ├── train.sh
│   │   ├── train_with_pre.sh
│   │   └── train_with_pre_raw.sh
│   ├── tokenizations       // 分词器
│   │   ├── thulac_dict
│   │   │   └── seg
│   │   ├── bpe_tokenizer.py
│   │   ├── encoder.json
│   │   ├── tokenization_bert.py
│   │   ├── tokenization_bert_word_level.py
│   │   └── vocab.bpe
│   ├── LICENSE
│   ├── README.md
│   ├── eval.py             // 评估代码
│   ├── generate_class.py   // 模型生成接口类
│   ├── generate_loop.py
│   ├── requirements.txt
└── └── train.py            // 训练代码
```
